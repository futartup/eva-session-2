{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RedCarGAN-Train-SpectralNormalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyajitghana/TSAI-DeepVision-EVA4.0-Phase-2/blob/master/06-GenerativeAdversarialNetworks/RedCarGAN_Train_SpectralNormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxlkxvkrCyin",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "1c8d8cc0-8c4c-4e25-e420-6031e94dd6ba"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Sep 10 10:52:14 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P0    28W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyDODoaWC6KI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "ace8eafc-5371-4a88-a269-e3720ff78ce4"
      },
      "source": [
        "! git clone https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0-Phase-2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TSAI-DeepVision-EVA4.0-Phase-2'...\n",
            "remote: Enumerating objects: 3063, done.\u001b[K\n",
            "remote: Counting objects: 100% (3063/3063), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3037/3037), done.\u001b[K\n",
            "remote: Total 3527 (delta 50), reused 3015 (delta 24), pack-reused 464\u001b[K\n",
            "Receiving objects: 100% (3527/3527), 96.60 MiB | 41.54 MiB/s, done.\n",
            "Resolving deltas: 100% (196/196), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G46-ivQGpQcF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5009e08b-06f4-4528-94a9-acb00470a102"
      },
      "source": [
        "%cd /content/TSAI-DeepVision-EVA4.0-Phase-2/06-GenerativeAdversarialNetworks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TSAI-DeepVision-EVA4.0-Phase-2/06-GenerativeAdversarialNetworks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKAq-6SspR97",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "97ba62eb-2efc-49ec-b081-c56a7a87142b"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcar_images\u001b[0m/  \u001b[01;34mcar_images_100x100\u001b[0m/  DatasetCreation.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qecx01YpWET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as T\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-g_EWDvphmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from torch.nn import Parameter\n",
        "\n",
        "def l2normalize(v, eps=1e-12):\n",
        "    return v / (v.norm() + eps)\n",
        "\n",
        "\n",
        "class SpectralNorm(nn.Module):\n",
        "    def __init__(self, module, name='weight', power_iterations=1):\n",
        "        super(SpectralNorm, self).__init__()\n",
        "        self.module = module\n",
        "        self.name = name\n",
        "        self.power_iterations = power_iterations\n",
        "        if not self._made_params():\n",
        "            self._make_params()\n",
        "\n",
        "    def _update_u_v(self):\n",
        "        u = getattr(self.module, self.name + \"_u\")\n",
        "        v = getattr(self.module, self.name + \"_v\")\n",
        "        w = getattr(self.module, self.name + \"_bar\")\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        for _ in range(self.power_iterations):\n",
        "            v.data = l2normalize(torch.mv(torch.t(w.view(height,-1).data), u.data))\n",
        "            u.data = l2normalize(torch.mv(w.view(height,-1).data, v.data))\n",
        "\n",
        "        # sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))\n",
        "        sigma = u.dot(w.view(height, -1).mv(v))\n",
        "        setattr(self.module, self.name, w / sigma.expand_as(w))\n",
        "\n",
        "    def _made_params(self):\n",
        "        try:\n",
        "            u = getattr(self.module, self.name + \"_u\")\n",
        "            v = getattr(self.module, self.name + \"_v\")\n",
        "            w = getattr(self.module, self.name + \"_bar\")\n",
        "            return True\n",
        "        except AttributeError:\n",
        "            return False\n",
        "\n",
        "\n",
        "    def _make_params(self):\n",
        "        w = getattr(self.module, self.name)\n",
        "\n",
        "        height = w.data.shape[0]\n",
        "        width = w.view(height, -1).data.shape[1]\n",
        "\n",
        "        u = Parameter(w.data.new(height).normal_(0, 1), requires_grad=False)\n",
        "        v = Parameter(w.data.new(width).normal_(0, 1), requires_grad=False)\n",
        "        u.data = l2normalize(u.data)\n",
        "        v.data = l2normalize(v.data)\n",
        "        w_bar = Parameter(w.data)\n",
        "\n",
        "        del self.module._parameters[self.name]\n",
        "\n",
        "        self.module.register_parameter(self.name + \"_u\", u)\n",
        "        self.module.register_parameter(self.name + \"_v\", v)\n",
        "        self.module.register_parameter(self.name + \"_bar\", w_bar)\n",
        "\n",
        "\n",
        "    def forward(self, *args):\n",
        "        self._update_u_v()\n",
        "        return self.module.forward(*args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcM5s484puBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ResNet generator and discriminator\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "channels = 3\n",
        "\n",
        "class ResBlockGenerator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlockGenerator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform(self.conv2.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            self.conv1,\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            self.conv2\n",
        "            )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "            self.bypass = nn.Upsample(scale_factor=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "\n",
        "class ResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(ResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        nn.init.xavier_uniform(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform(self.conv2.weight.data, 1.)\n",
        "\n",
        "        if stride == 1:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                SpectralNorm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                SpectralNorm(self.conv2)\n",
        "                )\n",
        "        else:\n",
        "            self.model = nn.Sequential(\n",
        "                nn.ReLU(),\n",
        "                SpectralNorm(self.conv1),\n",
        "                nn.ReLU(),\n",
        "                SpectralNorm(self.conv2),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "                )\n",
        "        self.bypass = nn.Sequential()\n",
        "        if stride != 1:\n",
        "\n",
        "            self.bypass_conv = nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)\n",
        "            nn.init.xavier_uniform(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "            self.bypass = nn.Sequential(\n",
        "                SpectralNorm(self.bypass_conv),\n",
        "                nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            )\n",
        "            # if in_channels == out_channels:\n",
        "            #     self.bypass = nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            # else:\n",
        "            #     self.bypass = nn.Sequential(\n",
        "            #         SpectralNorm(nn.Conv2d(in_channels,out_channels, 1, 1, padding=0)),\n",
        "            #         nn.AvgPool2d(2, stride=stride, padding=0)\n",
        "            #     )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "# special ResBlock just for the first layer of the discriminator\n",
        "class FirstResBlockDiscriminator(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(FirstResBlockDiscriminator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, 1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, padding=1)\n",
        "        self.bypass_conv = nn.Conv2d(in_channels, out_channels, 1, 1, padding=0)\n",
        "        nn.init.xavier_uniform(self.conv1.weight.data, 1.)\n",
        "        nn.init.xavier_uniform(self.conv2.weight.data, 1.)\n",
        "        nn.init.xavier_uniform(self.bypass_conv.weight.data, np.sqrt(2))\n",
        "\n",
        "        # we don't want to apply ReLU activation to raw image before convolution transformation.\n",
        "        self.model = nn.Sequential(\n",
        "            SpectralNorm(self.conv1),\n",
        "            nn.ReLU(),\n",
        "            SpectralNorm(self.conv2),\n",
        "            nn.AvgPool2d(2)\n",
        "            )\n",
        "        self.bypass = nn.Sequential(\n",
        "            nn.AvgPool2d(2),\n",
        "            SpectralNorm(self.bypass_conv),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) + self.bypass(x)\n",
        "\n",
        "GEN_SIZE=128\n",
        "DISC_SIZE=128\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.dense = nn.Linear(self.z_dim, 4 * 4 * GEN_SIZE)\n",
        "        self.final = nn.Conv2d(GEN_SIZE, channels, 3, stride=1, padding=1)\n",
        "        nn.init.xavier_uniform(self.dense.weight.data, 1.)\n",
        "        nn.init.xavier_uniform(self.final.weight.data, 1.)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            ResBlockGenerator(GEN_SIZE, GEN_SIZE, stride=2),\n",
        "            ResBlockGenerator(GEN_SIZE, GEN_SIZE, stride=2),\n",
        "            ResBlockGenerator(GEN_SIZE, GEN_SIZE, stride=2),\n",
        "            nn.BatchNorm2d(GEN_SIZE),\n",
        "            nn.ReLU(),\n",
        "            self.final,\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.model(self.dense(z).view(-1, GEN_SIZE, 4, 4))\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "                FirstResBlockDiscriminator(channels, DISC_SIZE, stride=2),\n",
        "                ResBlockDiscriminator(DISC_SIZE, DISC_SIZE, stride=2),\n",
        "                ResBlockDiscriminator(DISC_SIZE, DISC_SIZE),\n",
        "                ResBlockDiscriminator(DISC_SIZE, DISC_SIZE),\n",
        "                nn.ReLU(),\n",
        "                nn.AvgPool2d(8),\n",
        "            )\n",
        "        self.fc = nn.Linear(DISC_SIZE, 1)\n",
        "        nn.init.xavier_uniform(self.fc.weight.data, 1.)\n",
        "        self.fc = SpectralNorm(self.fc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fc(self.model(x).view(-1,DISC_SIZE))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GAEvG4qpwEh",
        "colab_type": "text"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3N5ZBKfbpuLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9lgWkpHpxuz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = T.Compose([\n",
        "                        T.ToTensor(),\n",
        "                        T.Normalize(mean=[0.570838093757629, 0.479552984237671, 0.491760671138763], std=[0.279659748077393, 0.309973508119583, 0.311098515987396])\n",
        "                        ])\n",
        "dataset = ImageFolder('car_images_100x100', transform=transforms)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=True, num_workers=2, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TbgSPEZpy-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Z_dim = 128\n",
        "# number of updates to discriminator for every update to generator \n",
        "disc_iters = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j044j1-Zp0tb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "42497e72-90d9-4f43-cc39-dda52de263d0"
      },
      "source": [
        "discriminator = Discriminator().to(device)\n",
        "generator = Generator(Z_dim).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:93: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:95: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:44: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:66: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:150: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:122: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:123: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--jE1t5bp25z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# because the spectral normalization module creates parameters that don't require gradients (u and v), we don't want to \n",
        "# optimize these using sgd. We only let the optimizer operate on parameters that _do_ require gradients\n",
        "# TODO: replace Parameters with buffers, which aren't returned from .parameters() method.\n",
        "optim_disc = optim.Adam(filter(lambda p: p.requires_grad, discriminator.parameters()), lr=2e-4, betas=(0.0, 0.9))\n",
        "optim_gen  = optim.Adam(generator.parameters(), lr=2e-4, betas=(0.0, 0.9))\n",
        "\n",
        "# use an exponentially decaying learning rate\n",
        "scheduler_d = optim.lr_scheduler.ExponentialLR(optim_disc, gamma=0.99)\n",
        "scheduler_g = optim.lr_scheduler.ExponentialLR(optim_gen, gamma=0.99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aNPLndUp4h-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    for batch_idx, (data, target) in enumerate(dataloader):\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # update discriminator\n",
        "        for _ in range(disc_iters):\n",
        "            z = Variable(torch.randn(128, Z_dim).to(device))\n",
        "            optim_disc.zero_grad()\n",
        "            optim_gen.zero_grad()\n",
        "\n",
        "            disc_loss = nn.ReLU()(1.0 - discriminator(data)).mean() + nn.ReLU()(1.0 + discriminator(generator(z))).mean()\n",
        "\n",
        "            disc_loss.backward()\n",
        "            optim_disc.step()\n",
        "\n",
        "        z = Variable(torch.randn(128, Z_dim).to(device))\n",
        "\n",
        "        # update generator\n",
        "        optim_disc.zero_grad()\n",
        "        optim_gen.zero_grad()\n",
        "\n",
        "        gen_loss = -discriminator(generator(z)).mean()\n",
        "        gen_loss.backward()\n",
        "        optim_gen.step()\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('=> disc loss', disc_loss.item(), 'gen loss', gen_loss.item())\n",
        "    scheduler_d.step()\n",
        "    scheduler_g.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un22tKzIp6fH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_z = Variable(torch.randn(128, Z_dim).to(device))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1eXwU_Fp7rP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(epoch):\n",
        "\n",
        "    samples = generator(fixed_z).cpu().data.numpy()[:64]\n",
        "\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    gs = gridspec.GridSpec(8, 8)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, sample in enumerate(samples):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis('off')\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect('equal')\n",
        "        plt.imshow(sample.transpose((1, 2, 0)) * 0.5 + 0.5)\n",
        "\n",
        "    if not os.path.exists('out/'):\n",
        "        os.makedirs('out/')\n",
        "\n",
        "    plt.savefig('out/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
        "    plt.close(fig)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whV7J2L1p_aR",
        "colab_type": "text"
      },
      "source": [
        "## Start Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4dIzXc0p8wf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "015ce916-edb0-4d15-8cb3-a29bc1205036"
      },
      "source": [
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "\n",
        "for epoch in range(10):\n",
        "    train(epoch)\n",
        "    evaluate(epoch)\n",
        "    torch.save(discriminator.state_dict(), os.path.join('checkpoints', 'disc_{}'.format(epoch)))\n",
        "    torch.save(generator.state_dict(), os.path.join('checkpoints', 'gen_{}'.format(epoch)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=> disc loss -4214.4404296875 gen loss 1400.540283203125\n",
            "=> disc loss -5250.73193359375 gen loss 1244.3837890625\n",
            "=> disc loss -6190.486328125 gen loss 946.7943115234375\n",
            "=> disc loss -6924.486328125 gen loss 810.0628051757812\n",
            "=> disc loss -8720.5927734375 gen loss 880.4735107421875\n",
            "=> disc loss -10021.181640625 gen loss 736.32373046875\n",
            "=> disc loss -9589.9130859375 gen loss 1150.35498046875\n",
            "=> disc loss -10455.2099609375 gen loss 888.5648193359375\n",
            "=> disc loss -11913.6103515625 gen loss 877.2724609375\n",
            "=> disc loss -11980.5888671875 gen loss 1271.73388671875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBd_fcpbqA37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}